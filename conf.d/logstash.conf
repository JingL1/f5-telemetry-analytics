input {
    kafka {
        type => "kafka"
        bootstrap_servers => "kafka:9093"
        topics => [
            # "ml-8081", 8081 is used for elasticsearch performance test.
            "ml-8082",
            "ml-8083",
            "ml-8084", 
            "ml-8085",
            "ml-8086",
            "ml-8087",
            "ml-8088",
            "ml-8089", 
            "http-fluentd",
            "healthcheck"
        ]
        decorate_events => "true"
    }
}

# input {
#     tcp {
#         type => "test"
#         port => 4560
#         codec => json_lines
#     }
# }

filter {
    json {
        source => "message"
    }
}

filter {
    if ("" in [mesg_hex]) {
        if [mesg_hex] !~ /0$/ { # 1/16
        # if [mesg_hex] !~ /[0-7]$/ { # half
        # if [mesg_hex] !~ /[0-9a-z]$/ { # all
            drop {}
        }
    }
}

filter {
    if ([geo] == ",") { 
        mutate {
            add_field => {
                # cannot use 'HH', too many index may slow down elasticsearch startup speed.
                # index => "errlogs-%{+YYYY.MM.dd.HH}"
                index => "errlogs-%{+YYYY.MM.dd}"
                reason => "Faild to parse geo for %{[client-ip]}"
            }
        }
    }
    else {
        mutate {
            add_field => {
                # cannot use 'HH', too many index may slow down elasticsearch startup speed.
                # index => "%{[@metadata][kafka][topic]}-%{+YYYY.MM.dd.HH}"
                index => "%{[@metadata][kafka][topic]}-%{+YYYY.MM.dd}"
                # index => "all-http-fluentd-alias" # elastic alias doesn't work.
                # zongzw => "%{[@metadata][kafka][topic]}"
                # metadata :
                    # [@metadata][kafka][topic]: Original Kafka topic from where the message was consumed.
                    # [@metadata][kafka][consumer_group]: Consumer group
                    # [@metadata][kafka][partition]: Partition info for this message.
                    # [@metadata][kafka][offset]: Original record offset for this message.
                    # [@metadata][kafka][key]: Record key, if any.
                    # [@metadata][kafka][timestamp]: Timestamp when this message was received by the Kafka broker.
            }
        }
    }
    mutate {
        remove_field => [
            "@timestamp", # '%{+YYYY.MM.dd.HH}' will use @timestamp, so remove it here -- after add_field
            "message",   # comment this line for debug when looking into the original message
            "@version"
        ]
    }
}

output{
    if [stdout] == 'OK' {
        stdout { codec => rubydebug }
    }
    if [type] == "kafka" {
        elasticsearch { 
            hosts => ["elasticsearch:9200"]
            index => "%{[index]}"
        }
    }
}
